{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "we clean the accepted loans of Lending Club https://www.kaggle.com/wordsforthewise/lending-club to prepare for EDA and machine lerning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtypes = {'issue_d': 'str', 'sec_app_earliest_cr_line':'str', \n",
    "#           'earliest_cr_line':'str', 'last_pymnt_d':'str', \n",
    "#           'last_credit_pull_d':'str'}\n",
    "\n",
    "# accepted = pd.read_csv('/Users/ivanpassoni/Downloads/lending-club/accepted_2007_to_2018Q4.csv',\n",
    "#                        low_memory = False, dtype = dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping bad Id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove bad id's\n",
    "# accepted.drop(index= accepted.loc[accepted['id'].apply(lambda s: len(str(s))) > 10, :].index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parsing issue_date, last_pymnt_d, earliest_cr_line, last_credit_pull_d datetime\n",
    "# def parse_date(d):\n",
    "#     return pd.to_datetime(d, format='%b-%Y')\n",
    "\n",
    "# accepted['issue_d']            = accepted['issue_d'].apply(parse_date)\n",
    "# accepted['last_pymnt_d']       = accepted['last_pymnt_d'].apply(parse_date)\n",
    "# accepted['earliest_cr_line']   = accepted['earliest_cr_line'].apply(parse_date)\n",
    "# accepted['last_credit_pull_d'] = accepted['last_credit_pull_d'].apply(parse_date)\n",
    "# next_pymnt_d will be droped later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saved and reading the data parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accepted.to_csv('/Users/ivanpassoni/Downloads/lending-club/accepted_2007_to_2018Q4_parsed_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_dates = ['issue_d', 'last_pymnt_d', 'earliest_cr_line', 'last_credit_pull_d']\n",
    "\n",
    "accepted = pd.read_csv('/Users/ivanpassoni/Downloads/lending-club/accepted_2007_to_2018Q4_parsed_data.csv',\n",
    "                       low_memory = False, parse_dates = parse_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging joint and individual loan applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider a joint application as an individual application with the annual_inc, dti and revol_bal given by their joint values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering annual_inc == annual_inc_joint, dti == dti_joint\n",
    "accepted['annual_inc'] = accepted[['application_type', 'annual_inc', 'annual_inc_joint']]\\\n",
    ".apply(lambda row: row['annual_inc'] if row['application_type'] == 'Individual' else row['annual_inc_joint'], axis = 1)\n",
    "\n",
    "accepted['dti'] = accepted[['application_type', 'dti', 'dti_joint']]\\\n",
    ".apply(lambda row: row['dti'] if row['application_type'] == 'Individual' else row['dti_joint'], axis = 1)\n",
    "\n",
    "accepted['revol_bal'] = accepted[['application_type', 'revol_bal', 'revol_bal_joint']]\\\n",
    ".apply(lambda row: row['revol_bal'] if row['application_type'] == 'Individual' else row['revol_bal_joint'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Last Payment Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We impute the last_pymnt_d by adding to issue_d the number of months given by total_pymnt/installment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import timedelta\n",
    "\n",
    "def increment_months(s, length):\n",
    "    while length > 0:\n",
    "        if s.month == 12:\n",
    "            s = s + timedelta(days = 31)\n",
    "        else:\n",
    "            s = s + relativedelta(months = 1)\n",
    "        length -= 1\n",
    "    return s\n",
    "\n",
    "accepted['last_pymnt_d'].fillna(accepted.loc[accepted['last_pymnt_d'].isnull(), \n",
    "                                             ['issue_d', 'total_pymnt', 'installment']]\\\n",
    "                        .apply(lambda s: increment_months(s[0],np.floor(s[1]/s[2])), axis = 1),\n",
    "                                inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Apriori columns and droping irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apriori_columns = ['id', 'member_id', 'loan_amnt', 'funded_amnt', \n",
    "                   'funded_amnt_inv','term','int_rate',\n",
    "                   'installment','grade','sub_grade','emp_title',\n",
    "                   'emp_length','home_ownership', 'annual_inc',\n",
    "                   'issue_d','url','desc','purpose','title',\n",
    "                   'zip_code','addr_state','dti','delinq_2yrs',\n",
    "                   'earliest_cr_line','fico_range_low',\n",
    "                   'fico_range_high','inq_last_6mths',\n",
    "                   'mths_since_last_delinq','mths_since_last_record',\n",
    "                   'open_acc','pub_rec','revol_bal','revol_util',\n",
    "                   'total_acc','initial_list_status',\n",
    "                   'collections_12_mths_ex_med',\n",
    "                   'mths_since_last_major_derog','application_type',\n",
    "                   'annual_inc_joint','dti_joint','acc_now_delinq',\n",
    "                   'tot_coll_amt','tot_cur_bal','open_acc_6m',\n",
    "                   'open_act_il','open_il_12m','open_il_24m',\n",
    "                   'mths_since_rcnt_il','total_bal_il','il_util',\n",
    "                   'open_rv_12m','open_rv_24m','max_bal_bc','all_util',\n",
    "                   'total_rev_hi_lim','inq_fi','total_cu_tl','inq_last_12m',\n",
    "                   'acc_open_past_24mths','avg_cur_bal','bc_open_to_buy',\n",
    "                   'bc_util','chargeoff_within_12_mths','delinq_amnt',\n",
    "                   'mo_sin_old_rev_tl_op','mo_sin_rcnt_rev_tl_op',\n",
    "                   'mo_sin_rcnt_tl','mort_acc','mths_since_recent_bc',\n",
    "                   'mths_since_recent_revol_delinq','num_accts_ever_120_pd',\n",
    "                   'num_actv_bc_tl','num_actv_rev_tl','num_bc_sats','num_bc_tl',\n",
    "                   'num_il_tl','num_op_rev_tl','num_rev_accts',\n",
    "                   'num_rev_tl_bal_gt_0','num_sats','num_tl_120dpd_2m',\n",
    "                   'num_tl_30dpd','num_tl_90g_dpd_24m','num_tl_op_past_12m',\n",
    "                   'pct_tl_nvr_dlq','percent_bc_gt_75','pub_rec_bankruptcies',\n",
    "                   'tax_liens','tot_hi_cred_lim','total_bal_ex_mort',\n",
    "                   'total_bc_limit','total_il_high_credit_limit',\n",
    "                   'revol_bal_joint','sec_app_fico_range_low',\n",
    "                   'sec_app_fico_range_high','sec_app_earliest_cr_line',\n",
    "                   'sec_app_inq_last_6mths','sec_app_mort_acc',\n",
    "                   'sec_app_open_acc','sec_app_revol_util',\n",
    "                   'sec_app_open_act_il','sec_app_num_rev_accts',\n",
    "                   'sec_app_chargeoff_within_12_mths',\n",
    "                   'sec_app_collections_12_mths_ex_med',\n",
    "                   'sec_app_mths_since_last_major_derog', \n",
    "                   'disbursement_method']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Droping some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns\n",
    "hardships = [col for col in accepted.columns if 'hard' in col]\n",
    "hardships.extend(['payment_plan_start_date', 'orig_projected_additional_accrued_interest'])\n",
    "\n",
    "investors = [col for col in accepted.columns if 'inv' in col]\n",
    "\n",
    "secundary_applicants = [col for col in accepted.columns if 'sec' in col]\n",
    "\n",
    "settlements = [col for col in accepted.columns if 'settlement' in col]\n",
    "\n",
    "joint = [col for col in accepted.columns if 'joint' in col]\n",
    "\n",
    "drop_columns = ['member_id', 'url', 'desc', \n",
    "                'pymnt_plan', 'title', \n",
    "                'zip_code', 'disbursement_method',\n",
    "                'next_pymnt_d', 'policy_code',\n",
    "                'deferral_term', 'emp_title',\n",
    "                'application_type']               +\\\n",
    "                hardships + settlements           +\\\n",
    "                secundary_applicants + investors  +\\\n",
    "                joint\n",
    "\n",
    "accepted.drop(columns = drop_columns, inplace = True)\n",
    "\n",
    "# updating the apriori columns list\n",
    "\n",
    "apriori_columns = [col for col in apriori_columns if col not in drop_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping some rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted.drop(index=accepted.loc[((accepted['home_ownership'] == 'ANY')|\n",
    "                                 (accepted['home_ownership'] == 'OTHER')|\n",
    "                                  (accepted['home_ownership'] == 'NONE')), :].index,\n",
    "              inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subdividing the data by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_b_2015    = accepted.loc[accepted['issue_d'] < '2015-01-1', :]\n",
    "accepted_2015      = accepted.loc[(accepted['issue_d'] >= '2015-01-1') & (accepted['issue_d'] < '2016-01-1'), :]\n",
    "accepted_2016      = accepted.loc[(accepted['issue_d'] >= '2016-01-1') & (accepted['issue_d'] < '2017-01-1'), :]\n",
    "accepted_2017      = accepted.loc[(accepted['issue_d'] >= '2017-01-1') & (accepted['issue_d'] < '2018-01-1'), :]\n",
    "accepted_2018      = accepted.loc[(accepted['issue_d'] >= '2018-01-1') & (accepted['issue_d'] < '2019-01-1'), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [accepted_b_2015, accepted_2015, accepted_2016, accepted_2017, accepted_2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apriori_columns_bac = apriori_columns.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling the apriori columns NA's for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nas(df, apriori_columns):\n",
    "    apriori = apriori_columns.copy()\n",
    "    \n",
    "    df['pub_rec_bankruptcies'] = df['pub_rec_bankruptcies'].fillna(0) #almost all is 0\n",
    "    \n",
    "    null_sum = df[apriori].isnull().sum()\n",
    "    p_null_sum = null_sum[null_sum > 0]\n",
    "\n",
    "    # Droping observations with NA's that are in columns with low NA's\n",
    "    columns_na = p_null_sum[p_null_sum/df.shape[0]<.01].index\n",
    "\n",
    "    idx = df.loc[df[columns_na].isnull().any(axis=1), :].index\n",
    "    df = df.drop(index=idx)\n",
    "\n",
    "    null_sum = df[apriori].isnull().sum()\n",
    "    p_null_sum = null_sum[null_sum > 0]\n",
    "\n",
    "    # drop columns that have many NA's\n",
    "    drop_na_columns = p_null_sum[p_null_sum/df.shape[0]>.5].index\n",
    "\n",
    "    df.drop(columns = drop_na_columns, inplace = True)\n",
    "\n",
    "    apriori = [col for col in apriori if col not in drop_na_columns] #update apriori\n",
    "\n",
    "    null_sum = df[apriori].isnull().sum()\n",
    "    p_null_sum = null_sum[null_sum > 0]\n",
    "\n",
    "    # Fill emp_length NA's by random sampling proportionaly\n",
    "    a = df['emp_length'].value_counts()/df['emp_length'].shape[0]*1000\n",
    "    a = a.apply(lambda x: int(x))\n",
    "    x = pd.Series(range(1, np.sum(a)+1))\n",
    "\n",
    "    n = np.sum(df['emp_length'].isnull())\n",
    "\n",
    "    x = x.sample(n, replace = True).reset_index()\\\n",
    "    .set_index(df.loc[df['emp_length'].isnull(), 'emp_length'].index)[0]\n",
    "\n",
    "    df = df.fillna({'emp_length':pd.cut(x, bins = [0]+list(np.cumsum(a)), labels = a.index)})\n",
    "\n",
    "    null_sum = df[apriori].isnull().sum()\n",
    "    p_null_sum = null_sum[null_sum > 0]\n",
    "\n",
    "    #Fill the rest of apriori columns NA's by the median of the sub_grade\n",
    "    null_sum = df[apriori].isnull().sum()\n",
    "    for col in null_sum[null_sum > 0].index:\n",
    "        a  = df.groupby(['sub_grade'])[col].agg('median')\n",
    "        df = df.fillna({col:df.loc[df[col].isnull(), \n",
    "                       ['sub_grade', col]].apply(lambda s: a[s[0]], axis = 1)})\n",
    "\n",
    "    null_sum = df[apriori].isnull().sum()\n",
    "    p_null_sum = null_sum[null_sum > 0]\n",
    "\n",
    "    # removing all the non apriori columns with NA's, only keeping last_credit_pull_d\n",
    "    df = df.fillna({'last_credit_pull_d':np.mean(df['last_credit_pull_d'])})\n",
    "\n",
    "    columns_drop = df.isnull().sum()[df.isnull().sum() > 0].index\n",
    "    df = df.drop(columns = columns_drop)\n",
    "\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    return df, apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dfs = []\n",
    "for df in dfs:\n",
    "    clean_dfs.append(fill_nas(df, apriori_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engeniering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loan_length(d1, d2):\n",
    "    return (d1.year - d2.year) * 12 + d1.month - d2.month\n",
    "\n",
    "def calculate_duration(df):\n",
    "    loan_months = []\n",
    "    for end, start in zip(df['last_pymnt_d'], df['issue_d']):\n",
    "        loan_months.append(loan_length(end, start))\n",
    "        \n",
    "    days_in_dt = df['last_pymnt_d'] - df['issue_d']\n",
    "    \n",
    "    df['duration_days'] = days_in_dt.dt.days\n",
    "    df['duration_months'] = loan_months\n",
    "    return df\n",
    "\n",
    "def simplify_loan_status(df):\n",
    "    paid = ['Fully Paid', 'Does not meet the credit policy. Status:Fully Paid']\n",
    "\n",
    "    df.loc[:, 'loan_status'] = df['loan_status'].apply(lambda s: 'FullyPaid' if s in paid  else\n",
    "                                                                 'Current' if s=='Current' else\n",
    "                                                                 'Defaulted')\n",
    "    return df\n",
    "\n",
    "def calculate_invst_return(df):\n",
    "    df['invest_return_per'] = list(map(lambda x: round(x,2), \n",
    "                                          (df['total_pymnt'] - df['funded_amnt'])/df['funded_amnt']*100))\n",
    "    df['invest_return']     = list(map(lambda x: round(x,2), df['total_pymnt'] - df['funded_amnt']))\n",
    "    return df\n",
    "\n",
    "def calculate_fico_mid(df):\n",
    "    df['fico_mid'] = (df['fico_range_high'] + df['fico_range_low'])/2\n",
    "    return df\n",
    "\n",
    "def generate_features(df):\n",
    "    df = calculate_duration(df)\n",
    "    df = simplify_loan_status(df)\n",
    "    df = calculate_invst_return(df)\n",
    "    df = calculate_fico_mid(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_fg_dfs = []\n",
    "for df, _ in clean_dfs:\n",
    "    clean_fg_dfs.append(generate_features(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random permutation of the dataset\n",
    "for i, df in enumerate(clean_fg_dfs):\n",
    "    perm            = np.random.permutation(df.shape[0]) \n",
    "    clean_fg_dfs[i] = df.iloc[perm, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_loan_columns = ['verification_status', 'loan_status', 'out_prncp',\n",
    "                     'total_pymnt','total_rec_prncp','total_rec_int',\n",
    "                     'total_rec_late_fee', 'recoveries', \n",
    "                     'collection_recovery_fee', 'last_pymnt_d',\n",
    "                     'last_pymnt_amnt','last_credit_pull_d', \n",
    "                     'last_fico_range_high','last_fico_range_low']\n",
    "\n",
    "genereted_columns = ['duration_days','duration_months','invest_return_per',\n",
    "                     'invest_return']\n",
    "#Not sure about verification_status\n",
    "\n",
    "#Remove from features\n",
    "remove_columns = ['issue_d', 'id']\n",
    "\n",
    "\n",
    "counting_columns = ['delinq_2yrs','inq_last_6mths', 'open_acc', \n",
    "                    'pub_rec', 'total_acc', 'collections_12_mths_ex_med', \n",
    "                    'acc_now_delinq', 'chargeoff_within_12_mths', \n",
    "                    'mort_acc','num_accts_ever_120_pd', 'num_actv_bc_tl', \n",
    "                    'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl',\n",
    "                    'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats',\n",
    "                    'num_tl_120dpd_2m', 'num_tl_30dpd','num_tl_90g_dpd_24m', \n",
    "                    'num_tl_op_past_12m', 'pub_rec_bankruptcies', 'tax_liens',\n",
    "                    'acc_open_past_24mths', 'num_actv_rev_tl']\n",
    "\n",
    "\n",
    "# Categorical\n",
    "cat_columns = ['term', 'home_ownership', 'purpose', 'addr_state', 'initial_list_status']\n",
    "\n",
    "#Ordinal\n",
    "ordinal_columns = ['sub_grade', 'emp_length'] #grade is removed\n",
    "\n",
    "#earliest_cr_line is a datetime column and was removed. The rest is the number of months since something\n",
    "time_columns = ['mo_sin_old_rev_tl_op', 'mo_sin_rcnt_tl', \n",
    "                'mths_since_recent_bc','mo_sin_rcnt_rev_tl_op'] \n",
    "\n",
    "non_continuous_columns = counting_columns + cat_columns + ordinal_columns + time_columns\n",
    "continuous_columns = ['loan_amnt','funded_amnt','int_rate',\n",
    "                      'installment','annual_inc','dti',\n",
    "                      'fico_mid', 'revol_bal',\n",
    "                      'revol_util','tot_coll_amt',\n",
    "                      'tot_cur_bal','total_rev_hi_lim',\n",
    "                      'avg_cur_bal','bc_open_to_buy','bc_util',\n",
    "                      'delinq_amnt','pct_tl_nvr_dlq',\n",
    "                      'percent_bc_gt_75','tot_hi_cred_lim',\n",
    "                      'total_bal_ex_mort','total_bc_limit',\n",
    "                      'total_il_high_credit_limit']\n",
    "\n",
    "feature_columns = continuous_columns + non_continuous_columns\n",
    "\n",
    "keep_columns = remove_columns + feature_columns + post_loan_columns\n",
    "\n",
    "ml_columns = feature_columns + ['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dfs  = []\n",
    "for df in clean_fg_dfs:\n",
    "    final_dfs.append(df.loc[:, keep_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dfs = []\n",
    "for df in clean_fg_dfs:\n",
    "    model_dfs.append(df.loc[:, ml_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the new datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dfs[0].to_csv('/Users/ivanpassoni/Google Drive/LendingClubData/ml datasets/accepted_b_2015_ml.csv', index = False)\n",
    "\n",
    "for df, year in zip(model_dfs[1:], [2015, 2016, 2017, 2018]):\n",
    "    df.to_csv(f'/Users/ivanpassoni/Google Drive/LendingClubData/ml datasets/accepted_{year}_ml.csv',\n",
    "              index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dfs[0].to_csv('/Users/ivanpassoni/Google Drive/LendingClubData/accepted loans/accepted_b_2015.csv', index = False)\n",
    "\n",
    "for df in final_dfs[1:]:\n",
    "    df.to_csv('/Users/ivanpassoni/Google Drive/LendingClubData/accepted loans/accepted_' + str(df['issue_d'].max().year) + '.csv',\n",
    "              index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To read the dataset\n",
    "# parse_dates = ['issue_d', 'last_pymnt_d', 'earliest_cr_line', 'last_credit_pull_d']\n",
    "\n",
    "# accepted = pd.read_csv('/Users/ivanpassoni/Google Drive/LendingClubData/accepted_b_2015.csv',\n",
    "#                        low_memory = False, parse_dates = parse_dates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
