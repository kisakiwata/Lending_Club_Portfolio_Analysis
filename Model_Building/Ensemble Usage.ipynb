{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, precision_score, accuracy_score\n",
    "\n",
    "def score(y_true, y_pred):\n",
    "    A = confusion_matrix(y_true, y_pred)\n",
    "    print(\n",
    "    f''' \n",
    "    F1 score              | {round(f1_score(y_true, y_pred)*100, 2)}        \\n\n",
    "    -----------------------------\n",
    "    Precision score       | {round(precision_score(y_true, y_pred)*100, 2)} \\n\n",
    "    -----------------------------\n",
    "    Accuracy              | {round(accuracy_score(y_true, y_pred)*100, 2)}  \\n\n",
    "    -----------------------------\n",
    "    Confusion matrix | {A[0,0]} {A[0,1]}\n",
    "                       {A[1,0]} {A[1,1]}\n",
    "    '''\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "\n",
    "ord_encoder     = load('./models/encoders/ordinal_encoder.joblib')\n",
    "one_hot_encoder = load('./models/encoders/one_hot_encoder.joblib')\n",
    "std_sc          = load('./models/encoders/standard_scaler.joblib')\n",
    "\n",
    "def preprocessing(df):\n",
    "    df = df.drop(index=df.loc[df['loan_status']=='Current', :].index)\n",
    "    X = df.loc[df['sub_grade'].apply(lambda row: False if row[0] in ['A', 'B','C'] else True), :]\n",
    "    y = X['loan_status'].replace({'Defaulted':0, 'FullyPaid':1})\n",
    "    X = X.iloc[:, :-1]\n",
    "    \n",
    "    X_ord  = ord_encoder.transform(X)\n",
    "\n",
    "    X_oh   = one_hot_encoder.transform(X)\n",
    "\n",
    "    drop_first = ['term_1', 'home_ownership_1', 'purpose_1','addr_state_1',\n",
    "                  'initial_list_status_1','sub_grade_1','emp_length_1']\n",
    "    X_oh  = X_oh.drop(columns = drop_first)\n",
    "    \n",
    "    X_oh   = std_sc.transform(X_oh)\n",
    "    \n",
    "    return X_ord, X_oh, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from joblib import load\n",
    "\n",
    "model_rf    = load('./models/RandomForest_1.joblib')\n",
    "model_xgb   = load('./models/XGBoost_1.joblib')\n",
    "model_rf2   = load('./models/RandomForest_2.joblib')\n",
    "model_xgb2  = load('./models/XGBoost_2.joblib')\n",
    "model_lgbm  = load('./models/LGBM_1.joblib')\n",
    "model_logit = load('./models/logit.joblib')\n",
    "model_nn    = load_model('./models/shallowNN_1')\n",
    "\n",
    "models_ord = [model_rf, model_xgb, model_rf2, model_xgb2, model_lgbm] \n",
    "models_oh  = [model_logit, model_nn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def ensemble(X_ord, X_oh, models_ord, models_oh, treshold = None):\n",
    "    if treshold == None:\n",
    "        treshold = (len(models_ord)+ len(models_oh))//2 + 1\n",
    "    predictions = []\n",
    "    for model in models_ord:\n",
    "        predictions.append(pd.Series(model.predict(X_ord)))\n",
    "    for model in models_oh:\n",
    "        predictions.append(pd.Series(model.predict(X_oh).reshape(-1)).apply(lambda x: 1 if x > .5 else 0))\n",
    "    \n",
    "    y_sum = reduce(lambda x, y: x+y, predictions)\n",
    "    return y_sum.apply(lambda x: 1 if x >= treshold else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2015 =  pd.read_csv('/Users/ivanpassoni/Google Drive/LendingClubData/ml datasets/accepted_2015_ml.csv',\n",
    "                        low_memory = False)\n",
    "test2016 =  pd.read_csv('/Users/ivanpassoni/Google Drive/LendingClubData/ml datasets/accepted_2016_ml.csv',\n",
    "                        low_memory = False)\n",
    "test2017 =  pd.read_csv('/Users/ivanpassoni/Google Drive/LendingClubData/ml datasets/accepted_2017_ml.csv',\n",
    "                        low_memory = False)\n",
    "test2018 =  pd.read_csv('/Users/ivanpassoni/Google Drive/LendingClubData/ml datasets/accepted_2018_ml.csv',\n",
    "                        low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2015_ord, X_2015_oh, y_2015 = preprocessing(test2015)\n",
    "X_2016_ord, X_2016_oh, y_2016 = preprocessing(test2016)\n",
    "X_2017_ord, X_2017_oh, y_2017 = preprocessing(test2017)\n",
    "X_2018_ord, X_2018_oh, y_2018 = preprocessing(test2018)\n",
    "\n",
    "\n",
    "y_2015p = ensemble(X_2015_ord, X_2015_oh, models_ord, models_oh, 7)\n",
    "y_2016p = ensemble(X_2016_ord, X_2016_oh, models_ord, models_oh, 7)\n",
    "y_2017p = ensemble(X_2017_ord, X_2017_oh, models_ord, models_oh, 7)\n",
    "y_2018p = ensemble(X_2018_ord, X_2018_oh, models_ord, models_oh, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -------------2015-------------\n",
      " \n",
      "    F1 score              | 50.56        \n",
      "\n",
      "    -----------------------------\n",
      "    Precision score       | 76.47 \n",
      "\n",
      "    -----------------------------\n",
      "    Accuracy              | 54.41  \n",
      "\n",
      "    -----------------------------\n",
      "    Confusion matrix | 28458 6565\n",
      "                       35157 21331\n",
      "    \n",
      "Base case:\n",
      " \n",
      "    F1 score              | 76.34        \n",
      "\n",
      "    -----------------------------\n",
      "    Precision score       | 61.73 \n",
      "\n",
      "    -----------------------------\n",
      "    Accuracy              | 61.73  \n",
      "\n",
      "    -----------------------------\n",
      "    Confusion matrix | 0 35023\n",
      "                       0 56488\n",
      "    \n",
      "   -------------2016-------------\n",
      " \n",
      "    F1 score              | 51.61        \n",
      "\n",
      "    -----------------------------\n",
      "    Precision score       | 68.61 \n",
      "\n",
      "    -----------------------------\n",
      "    Accuracy              | 55.54  \n",
      "\n",
      "    -----------------------------\n",
      "    Confusion matrix | 22524 7673\n",
      "                       23779 16771\n",
      "    \n",
      "Base case:\n",
      " \n",
      "    F1 score              | 72.87        \n",
      "\n",
      "    -----------------------------\n",
      "    Precision score       | 57.32 \n",
      "\n",
      "    -----------------------------\n",
      "    Accuracy              | 57.32  \n",
      "\n",
      "    -----------------------------\n",
      "    Confusion matrix | 0 30197\n",
      "                       0 40550\n",
      "    \n",
      "   -------------2017-------------\n",
      " \n",
      "    F1 score              | 54.98        \n",
      "\n",
      "    -----------------------------\n",
      "    Precision score       | 65.94 \n",
      "\n",
      "    -----------------------------\n",
      "    Accuracy              | 56.63  \n",
      "\n",
      "    -----------------------------\n",
      "    Confusion matrix | 13257 6014\n",
      "                       13052 11643\n",
      "    \n",
      "Base case:\n",
      " \n",
      "    F1 score              | 71.93        \n",
      "\n",
      "    -----------------------------\n",
      "    Precision score       | 56.17 \n",
      "\n",
      "    -----------------------------\n",
      "    Accuracy              | 56.17  \n",
      "\n",
      "    -----------------------------\n",
      "    Confusion matrix | 0 19271\n",
      "                       0 24695\n",
      "    \n",
      "   -------------2018-------------\n",
      " \n",
      "    F1 score              | 55.73        \n",
      "\n",
      "    -----------------------------\n",
      "    Precision score       | 62.35 \n",
      "\n",
      "    -----------------------------\n",
      "    Accuracy              | 55.96  \n",
      "\n",
      "    -----------------------------\n",
      "    Confusion matrix | 5036 2983\n",
      "                       4868 4941\n",
      "    \n",
      "Base case:\n",
      " \n",
      "    F1 score              | 70.98        \n",
      "\n",
      "    -----------------------------\n",
      "    Precision score       | 55.02 \n",
      "\n",
      "    -----------------------------\n",
      "    Accuracy              | 55.02  \n",
      "\n",
      "    -----------------------------\n",
      "    Confusion matrix | 0 8019\n",
      "                       0 9809\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print ('   -------------2015-------------')\n",
    "score(y_2015, y_2015p)\n",
    "# Base\n",
    "print('Base case:')\n",
    "score(y_2015, pd.Series(np.ones(len(y_2015))))\n",
    "\n",
    "print ('   -------------2016-------------')\n",
    "score(y_2016, y_2016p)\n",
    "# Base\n",
    "print('Base case:')\n",
    "score(y_2016, pd.Series(np.ones(len(y_2016))))\n",
    "\n",
    "print ('   -------------2017-------------')\n",
    "score(y_2017, y_2017p)\n",
    "# Base\n",
    "print('Base case:')\n",
    "score(y_2017, pd.Series(np.ones(len(y_2017))))\n",
    "\n",
    "print ('   -------------2018-------------')\n",
    "score(y_2018, y_2018p)\n",
    "# Base\n",
    "print('Base case:')\n",
    "score(y_2018, pd.Series(np.ones(len(y_2018))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature importance for 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(X_2017_ord.columns, model_rf.feature_importances_)), key = lambda x: x[1], reverse = True)[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(X_2017_ord.columns, model_rf2.feature_importances_)), key = lambda x: x[1], reverse = True)[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(X_2017_ord.columns, model_xgb.feature_importances_)), key = lambda x: x[1], reverse = True)[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(X_2017_ord.columns, model_xgb2.feature_importances_)), key = lambda x: x[1], reverse = True)[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dti', 0.03867791068096083),\n",
       " ('installment', 0.03776187875117656),\n",
       " ('annual_inc', 0.036839043741227775),\n",
       " ('term', 0.03467896746104897),\n",
       " ('loan_amnt', 0.034568461077529776),\n",
       " ('funded_amnt', 0.03379422303286396),\n",
       " ('avg_cur_bal', 0.03080102477877579),\n",
       " ('int_rate', 0.030793023067356276),\n",
       " ('tot_hi_cred_lim', 0.02896460619232284)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(X_2017_ord.columns, model_lgbm.feature_importances_)), key = lambda x: x[1], reverse = True)[0:9]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
